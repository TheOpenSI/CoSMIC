{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9623a563-e1fc-4c31-b7fc-7b809c5119ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import llama_index\n",
    "from llama_index.core import SimpleDirectoryReader # to load docs\n",
    "from llama_index.core import Document\n",
    "\n",
    "from llama_index.core.prompts import PromptTemplate # generate prompt template with role\n",
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "from llama_index.core import ChatPromptTemplate\n",
    "\n",
    "from llama_index.core.response.notebook_utils import display_response # formatting\n",
    "\n",
    "\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM # llm\n",
    "\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding # embedding\n",
    "\n",
    "from llama_index.core import Settings # pass llm and embedding\n",
    "\n",
    "from llama_index.core import VectorStoreIndex # store vector store\n",
    "\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4d24ff6a-833c-4fb0-bab5-07387e8c33db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "de710676-db09-4ed8-aded-8db3bfee58ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/s448780/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(\"../finetune/.env\")\n",
    "hf_token = os.getenv(\"hf_token\")\n",
    "login(hf_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcec5c5d-ab78-4459-91b6-ad51e602af08",
   "metadata": {},
   "source": [
    "## embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d1d32efe-3d90-4986-ac4c-f1cd9c89be99",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "94f00384-6e50-4ee5-bfac-5d72586249f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9f8d23-a30c-423b-9bdd-968d0d7cec9c",
   "metadata": {},
   "source": [
    "## Loading documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c6c64c80-6944-4774-aa4a-804a261295ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"./test_doc\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ddb31dd3-3c6c-4eee-980d-d006d6c9086a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ucl_2023.pdf'}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books = set()\n",
    "for book in documents:\n",
    "  books.add(book.metadata[\"file_name\"])\n",
    "\n",
    "books"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7b8519-9ad2-4891-b99c-e24512b1bbb1",
   "metadata": {},
   "source": [
    "## vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "eb01de4f-63a5-48a7-af84-c465e96c610b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3013f732-f341-4f15-a2e5-77af390d4470",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index.storage_context.persist(persist_dir=\"./vector_store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5fdd62df-48e4-4956-8ab5-87453d318664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load from storage\n",
    "# from llama_index.core import StorageContext, load_index_from_storage\n",
    "# storage_context = StorageContext.from_defaults(persist_dir = \"./vector_store\")\n",
    "# vector_index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c86f2aba-2d99-475e-89b5-0696b35204f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_document = SimpleDirectoryReader(\"./new_test_doc/\", filename_as_id=True).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b87ed327-3168-44a9-b7f6-1aab1bd5b937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isinstance(new_document[0], Document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "507c94a2-6015-4e23-b2d6-e5613210dd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update_kwargs = {\n",
    "#     \"delete_kwargs\": {\"team\" : \"Real Madrid\"},\n",
    "#     \"insert_kwargs\": {\"Manchester City\"},\n",
    "# }\n",
    "# vector_index.delete_ref_doc(documents[0].get_doc_id, delete_kwargs = {\"delete_kwargs\" : \"how many titles does real madrid have?\"}, delete_from_docstore=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "16f0c6a2-8432-4513-b3d0-5d8371b3c9f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id_='6be5e8c3-04eb-461e-8cf3-26be69b44d2a', embedding=None, metadata={'filename': 'README.md', 'category': 'codebase'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='\\nContext\\nLLMs are a phenomenal piece of technology for knowledge generation and reasoning.\\nThey are pre-trained on large amounts of publicly available data.\\nHow do we best augment LLMs with our own private data?\\nWe need a comprehensive toolkit to help perform this data augmentation for LLMs.\\n\\nProposed Solution\\nThat\\'s where LlamaIndex comes in. LlamaIndex is a \"data framework\" to help\\nyou build LLM  apps. It provides the following tools:\\n\\nOffers data connectors to ingest your existing data sources and data formats\\n(APIs, PDFs, docs, SQL, etc.)\\nProvides ways to structure your data (indices, graphs) so that this data can be\\neasily used with LLMs.\\nProvides an advanced retrieval/query interface over your data:\\nFeed in any LLM input prompt, get back retrieved context and knowledge-augmented output.\\nAllows easy integrations with your outer application framework\\n(e.g. with LangChain, Flask, Docker, ChatGPT, anything else).\\nLlamaIndex provides tools for both beginner users and advanced users.\\nOur high-level API allows beginner users to use LlamaIndex to ingest and\\nquery their data in 5 lines of code. Our lower-level APIs allow advanced users to\\ncustomize and extend any module (data connectors, indices, retrievers, query engines,\\nreranking modules), to fit their needs.\\n', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = Document.example()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a43c7d1f-19e0-4844-868f-f9d632840812",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.text = \"Real Madrid won 15 UCL titles as of June 2024\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "46099529-b39b-40b4-a60b-2a81fc69122c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id_='6be5e8c3-04eb-461e-8cf3-26be69b44d2a', embedding=None, metadata={'filename': 'README.md', 'category': 'codebase'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Real Madrid won 15 UCL titles as of June 2024', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dbb4ddaf-62e4-4d3a-885f-13a3308ea8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index.insert(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "65e9b0b7-2895-49b0-967c-ed0d14c0c384",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** As of June 2024, Real Madrid has won 15 UCL titles."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Settings.llm = llm\n",
    "query_engine = vector_index.as_query_engine()\n",
    "response = query_engine.query(\"how many titles does real madrid have?\")\n",
    "display_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd0d0c0-64ac-4f76-be6b-dd6c3eed4f16",
   "metadata": {},
   "source": [
    "## loading the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b8647c7a-97fb-4d50-8ec0-ba171b1ebe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"Writer/camel-5b-hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "67cade64-ef4e-4eaa-986a-285233580a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_wrapper_prompt = PromptTemplate(\n",
    "    \"Always answer the question, even if the context isn't helpful.\"\n",
    "    \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "    \"### Instruction:\\n{query_str}\\n\\n### Response:\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c4397f98-f02f-4acb-9afb-11905d7f9e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40cf765d3d48439fb8d41a7c2996a5d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm = HuggingFaceLLM(\n",
    "    context_window=2048,\n",
    "    max_new_tokens=256,\n",
    "    generate_kwargs={\"temperature\": 0, \"do_sample\": False},\n",
    "    query_wrapper_prompt=query_wrapper_prompt,\n",
    "    tokenizer_name=model_id,\n",
    "    model_name=model_id,\n",
    "    device_map=\"auto\",\n",
    "    tokenizer_kwargs={\"max_length\": 2048},\n",
    "    model_kwargs={\"torch_dtype\": torch.float16, \"load_in_8bit\" : True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "17a4605c-7159-4755-baf4-a4e5b4154ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86eb0e19-23d8-4683-a476-65eb5a92565a",
   "metadata": {},
   "source": [
    "## query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ad73ff9-e167-4854-94d4-85ef5fd03498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings.llm = None\n",
    "query_engine = vector_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "01b0df30-ffbb-4623-adb2-9cfd208248e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Real Madrid won 14 UCL titles, with the most recent being in June 2023."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\"how many titles does real madrid have? use the most updated information\")\n",
    "display_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4e52dbab-d6e9-42c9-b162-2c2bb496d98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='Real Madrid won 14 UCL titles, with the most recent being in June 2023.', source_nodes=[NodeWithScore(node=TextNode(id_='266ef5b4-1dec-4bbf-9258-89d8f38b37ec', embedding=None, metadata={'page_label': '1', 'file_name': 'ucl_2023.pdf', 'file_path': '/home/s448780/workspace/cognitive_ai/RAG/test_doc/ucl_2023.pdf', 'file_type': 'application/pdf', 'file_size': 10481, 'creation_date': '2024-06-17', 'last_modified_date': '2024-06-17'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='70ddeb15-3a3a-461a-a272-79d46a795af7', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '1', 'file_name': 'ucl_2023.pdf', 'file_path': '/home/s448780/workspace/cognitive_ai/RAG/test_doc/ucl_2023.pdf', 'file_type': 'application/pdf', 'file_size': 10481, 'creation_date': '2024-06-17', 'last_modified_date': '2024-06-17'}, hash='3bdd73affef35b5629e979222d7e6daf1d033d83ef90833bcc4536fafd1179ce')}, text='Real Madrid won 14 UCL titles\\nPublished on June, 2023', start_char_idx=0, end_char_idx=53, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.6828654816217644)], metadata={'266ef5b4-1dec-4bbf-9258-89d8f38b37ec': {'page_label': '1', 'file_name': 'ucl_2023.pdf', 'file_path': '/home/s448780/workspace/cognitive_ai/RAG/test_doc/ucl_2023.pdf', 'file_type': 'application/pdf', 'file_size': 10481, 'creation_date': '2024-06-17', 'last_modified_date': '2024-06-17'}})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "719c72d6-1957-4cc5-abaf-42f20130fe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = SimpleDirectoryReader(\"./new/\").load_data()\n",
    "new_store = VectorStoreIndex.from_documents(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0622fbd5-7840-4b2e-a8ed-3b2ef9ee3a3d",
   "metadata": {},
   "source": [
    "## update vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "86799943-adbb-4c85-b073-45ac2c86deb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jun 18, 2024'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date\n",
    "date.today().strftime(\"%b %d, %Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "11bf5f52-f83b-48ad-a859-06bd767be655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Real Madrid has 15 UCL titles as of Jun 18, 2024'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the function will trigger only when __update__store__ is present in the query\n",
    "update_query = f\"__update__store__ Real Madrid has 15 UCL titles as of {date.today().strftime('%b %d, %Y')} \"\n",
    "update_query.split(\"__update__store__\")[-1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "70ea58ea-72ed-463a-bc4f-233c31211254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "llama_index.core.indices.vector_store.base.VectorStoreIndex"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vector_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c583dbad-0494-40bc-b809-80936a29eedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_vector_store(text_to_add : str, vector_index : llama_index.core.indices.vector_store.base.VectorStoreIndex) -> None:\n",
    "    if not \"__update__store__\" in text_to_add:\n",
    "        print(\"No information to add\")\n",
    "        return\n",
    "    document_to_add = Document.example()\n",
    "    info = text_to_add.split(\"__update__store__\")[-1].strip()\n",
    "    document_to_add.text = info\n",
    "    vector_index.insert(document_to_add)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
