{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4cee869-9d96-4320-8745-2918f8666188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pprint import pprint\n",
    "import bitsandbytes as bnb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import notebook_login\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftConfig,\n",
    "    PeftModel,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "757f493e-2b8f-4697-9b57-c52b9c0f0cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab6e5b363f2a448fb1ff8c29c8e82b58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a519c0ac-5701-4a69-8d84-91690a0416fe",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f8ffe7a-8201-4bde-a6ca-75cb41db7edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['moves', 'explanation'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"csv\", data_files=\"./filtered_data/data.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86194a2b-eff7-4ff7-9af1-69f3fd5f9f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_instruction(sample):\n",
    "    return f\"\"\"You are a chess expert. Explain the rationale behind the last move from the given chess moves in Algebraic notation - \n",
    "        {sample[\"moves\"]}\n",
    "\n",
    "        ### Response:\n",
    "        {sample[\"explanation\"]}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80c8540d-a3d4-44d9-bdfb-b37381504d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a chess expert. Explain the rationale behind the last move from the given chess moves in Algebraic notation - \n",
      "        e4 e6 d4 b6 e5 Bb7 Nf3 h6 Bd3 g5 O-O g4 Nfd2 h5 Ne4 Nc6 Be3 Qe7 Qd2 Bh6 Bxh6 Nxh6 Nf6+ Kd8 Bh7 Nf5 Bxf5 exf5 c3 h4 Qg5 g3 fxg3 hxg3 Qxg3 Qf8 Rxf5 Ne7 Rg5 Ng6 Nd2 Qh6 Rh5 Qg7 Qg4 Bc8 Rxh8+ Qxh8 Rf1 d6 Qg5 Qh4 Qe3 Bb7 e6\n",
      "\n",
      "        ### Response:\n",
      "        ### Game Analysis\n",
      "\n",
      "**Move Pair 1:** \n",
      "- **White: e4**: White opens with the most common 1.e4 move, aiming for central control and freeing the bishop and queen.\n",
      "- **Black: e6**: Black responds with the French Defense, a solid choice, intending to challenge the center with d5 later.\n",
      "\n",
      "**Move Pair 2:** \n",
      "- **White: d4**: White aims to further control the center and allows for the development of the bishop.\n",
      "- **Black: b6**: Black prepares to fianchetto the light-squared bishop, potentially targeting the e4 pawn.\n",
      "\n",
      "**Move Pair 3:**\n",
      "- **White: e5**: White advances the pawn, gaining more space in the center and setting up an advance on the kingside.\n",
      "- **Black: Bb7**: Black fianchettos the bishop, targeting the central pawns and aiming to contest the center indirectly.\n",
      "\n",
      "**Move Pair 4:**\n",
      "- **White: Nf3**: White develops the knight, putting pressure on the e5 pawn and preparing to castle.\n",
      "- **Black: h6**: Black prevents the g5 move, which could displace the knight or create tactical opportunities for White.\n",
      "\n",
      "**Move Pair 5:**\n",
      "- **White: Bd3**: White develops the bishop, eyeing the h7-pawn and preparing to castle.\n",
      "- **Black: g5**: Black launches a pawn storm on the kingside, possibly aiming to create counterplay or disrupt Whiteâ€™s plans.\n",
      "\n",
      "**Move Pair 6:**\n",
      "- **White: O-O**: White castles, ensuring king safety and connecting the rooks.\n",
      "- **Black: g4**: Black continues the aggressive pawn push, attacking the knight on f3.\n",
      "\n",
      "**Move Pair 7:**\n",
      "- **White: Nfd2**: White repositions the knight, aiming to reroute it to more active squares or prepare the c4 pawn break.\n",
      "- **Black: h5**: Black supports the g4 pawn and continues the aggressive approach on the kingside.\n",
      "\n",
      "**Move Pair 8:**\n",
      "- **White: Ne4**: White centralizes the knight, putting pressure on Blackâ€™s position and aiming at key squares.\n",
      "- **Black: Nc6**: Black develops the knight, attacking the e5 pawn.\n",
      "\n",
      "**Move Pair 9:**\n",
      "- **White: Be3**: White develops the bishop and supports the d4 pawn.\n",
      "- **Black: Qe7**: Black prepares to connect rooks and possibly play O-O-O for castling.\n",
      "\n",
      "**Move Pair 10:**\n",
      "- **White: Qd2**: White connects the rooks and prepares for a possible Bh6 move to exchange Blackâ€™s active bishop.\n",
      "- **Black: Bh6**: Black aims to exchange Whiteâ€™s bishop and counter the threat of Bh6 by White.\n",
      "\n",
      "**Move Pair 11:**\n",
      "- **White: Bxh6**: White captures the bishop, removing a defensive piece for Black.\n",
      "- **Black: Nxh6**: Black recaptures, placing the knight back into play.\n",
      "\n",
      "**Move Pair 12:**\n",
      "- **White: Nf6+**: A forcing move, checking the Black king and disrupting Blackâ€™s coordination.\n",
      "- **Black: Kd8**: Black moves the king, unable to castle anymore.\n",
      "\n",
      "**Move Pair 13:**\n",
      "- **White: Bh7**: White checks the king and places the bishop in a more active position.\n",
      "- **Black: Nf5**: Black develops the knight, offering a trade or attacking the bishop.\n",
      "\n",
      "**Move Pair 14:**\n",
      "- **White: Bxf5**: White captures the knight, further opening Blackâ€™s kingside.\n",
      "- **Black: exf5**: Black recaptures, accepting doubled pawns but opening up the e-file for the queen or rook.\n",
      "\n",
      "**Move Pair 15:**\n",
      "- **White: c3**: White prepares to solidify the center and protect the d4 pawn.\n",
      "- **Black: h4**: Black continues to push pawns on the kingside, aiming at Whiteâ€™s position.\n",
      "\n",
      "**Move Pair 16:**\n",
      "- **White: Qg5**: White places the queen on a commanding square, eyeing tactical opportunities against Blackâ€™s king.\n",
      "- **Black: g3**: Black sacrifices the g-pawn to open lines against Whiteâ€™s king.\n",
      "\n",
      "**Move Pair 17:**\n",
      "- **White: fxg3**: White captures the pawn, opening the g-file and threatening Blackâ€™s kingside.\n",
      "- **Black: hxg3**: Black recaptures, maintaining open lines and potential threats.\n",
      "\n",
      "**Move Pair 18:**\n",
      "- **White: Qxg3**: White captures another pawn, consolidating a material advantage.\n",
      "- **Black: Qf8**: Black retreats the queen, defending key squares and preparing counterattacks.\n",
      "\n",
      "**Move Pair 19:**\n",
      "- **White: Rxf5**: White captures another pawn, threatening Qg5+, aiming to simplify the position advantageously.\n",
      "- **Black: Ne7**: Black blocks the check and deploys the knight defensively.\n",
      "\n",
      "**Move Pair 20:**\n",
      "- **White: Rg5**: White prepares to bring the rook to the g-file, exerting pressure on Blackâ€™s position.\n",
      "- **Black: Ng6**: Black aims to exchange or challenge the rook on g5.\n",
      "\n",
      "**Move Pair 21:**\n",
      "- **White: Nd2**: White reroutes the knight, aiming for a better position or supporting the c4 pawn break.\n",
      "- **Black: Qh6**: Black positions the queen aggressively, eyeing the kingside.\n",
      "\n",
      "**Move Pair 22:**\n",
      "- **White: Rh5**: White eyes the h-file, preparing threats against Blackâ€™s kingside.\n",
      "- **Black: Qg7**: Black retreats the queen, defending critical squares and preventing immediate threats.\n",
      "\n",
      "**Move Pair 23:**\n",
      "- **White: Qg4**: White offers queen exchange, simplifying the position and maintaining the upper hand.\n",
      "- **Black: Bc8**: Black retreats the bishop to defend and potentially reposition.\n",
      "\n",
      "**Move Pair 24:**\n",
      "- **White: Rxh8+**: White sacrifices the exchange to open lines and simplify the position favorably.\n",
      "- **Black: Qxh8**: Black recaptures, hoping to maintain counterplay possibilities.\n",
      "\n",
      "**Move Pair 25:**\n",
      "- **White: Rf1**: White centralizes the rook, aiming for pressure along the open file.\n",
      "- **Black: d6**: Black tries to open lines and gain some counterplay with pawn breaks.\n",
      "\n",
      "**Move Pair 26:**\n",
      "- **White: Qg5**: White places the queen aggressively, eyeing crucial squares and preparing Qe6.\n",
      "- **Black: Qh4**: Black brings the queen to threaten checks and counterplay.\n",
      "\n",
      "**Move Pair 27:**\n",
      "- **White: Qe3**: White places the queen on a commanding square, targeting weaknesses.\n",
      "- **Black: Bb7**: Black develops the final piece, eyeing potential counterattacks.\n",
      "\n",
      "**Move Pair 28:**\n",
      "- **White: e6**: White pushes the pawn into Blackâ€™s territory, creating significant threats and a winning position.\n",
      "\n",
      "### Summary of Strategy Used and Winner\n",
      "\n",
      "**Strategies Used:**\n",
      "- **Central Control**: White consistently aimed to control the center with pawns (e4, d4) and piece placement.\n",
      "- **Kingside Attack**: Both players focus on aggressive pawn moves and piece attacks on the kingside.\n",
      "- **Piece Coordination**: White's pieces were well-coordinated, with knights and bishops playing active roles.\n",
      "- **Material Gains**: White captured Black's pawns and established better material positions without giving Black strong counterplay.\n",
      "- **Simplifying the Position**: Exchanges were played favorably to simplify the position while maintaining the material advantage.\n",
      "\n",
      "**Winner:**\n",
      "- **White** wins. White's final move, pushing the e6 pawn, creates an overwhelming threat that Black cannot counter effectively. The black king's precarious position without castling and the material disadvantage led to White achieving a winning position.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "sample = dataset[\"train\"][0]\n",
    "print(format_instruction(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5483d5-9f69-4e2d-9e1e-52ef4a7de5e0",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8259f4c-4baa-44ae-b60b-2dabe4b4c0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14cfc702-d836-4b74-8e55-953924106b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c95fbf3ca95f4e5893857e2617241ad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "\n",
    "# load model \n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, \n",
    "    quantization_config=bnb_config, \n",
    "    use_cache=False, \n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model.config.pretraining_tp = 1 #parallel GPU\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eecd022-08ab-4266-b7c8-c433f8d9b978",
   "metadata": {},
   "source": [
    "## LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6a96ed4-c3c4-4130-89aa-4cfa5469bb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "lora_alpha - scaling factor applied to the low-rank matrices. It helps in balancing the contribution of the low-rank update to the original weights. \n",
    "Higher values of lora_alpha can increase the influence of the low-rank updates. It's a form of regularization to ensure the model doesn't deviate too much from the original weights.\n",
    "\n",
    "bias - \"none\", \"all\", or \"lora_only\".\n",
    "need more research on this.\n",
    "\n",
    "'''\n",
    "peft_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64, \n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05,\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1eada9b-37ec-45d1-8f45-25ff358baa54",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c17de554-89ef-4f6e-a16e-4b587a3bdaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41287cb9-7c68-42fb-9ff7-e32a7c16b07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s448780/miniconda3/envs/pydev/lib/python3.8/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, packing. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/s448780/miniconda3/envs/pydev/lib/python3.8/site-packages/transformers/training_args.py:1965: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of ðŸ¤— Transformers. Use `--hub_token` instead.\n",
      "  warnings.warn(\n",
      "/home/s448780/miniconda3/envs/pydev/lib/python3.8/site-packages/trl/trainer/sft_trainer.py:181: UserWarning: You passed a `packing` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/home/s448780/miniconda3/envs/pydev/lib/python3.8/site-packages/trl/trainer/sft_trainer.py:269: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc397bd8c6640409311a5a9ff27627c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s448780/miniconda3/envs/pydev/lib/python3.8/site-packages/trl/trainer/sft_trainer.py:397: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "/home/s448780/miniconda3/envs/pydev/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='219' max='219' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [219/219 1:05:05, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.976400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.889700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.845000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.783900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.720200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.751500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.737300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.649300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.602000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.600800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s448780/miniconda3/envs/pydev/lib/python3.8/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/s448780/miniconda3/envs/pydev/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/s448780/miniconda3/envs/pydev/lib/python3.8/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/s448780/miniconda3/envs/pydev/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/s448780/miniconda3/envs/pydev/lib/python3.8/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=219, training_loss=0.7448688533208142, metrics={'train_runtime': 3923.4628, 'train_samples_per_second': 0.444, 'train_steps_per_second': 0.056, 'total_flos': 1.5411741419844403e+17, 'train_loss': 0.7448688533208142, 'epoch': 3.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "model_args = TrainingArguments(\n",
    "    output_dir=\"mistral-7b\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    gradient_checkpointing=True,\n",
    "    optim=\"paged_adamw_32bit\", # apparently more efficient for 32 bit GPUs\n",
    "    logging_steps=20,\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-4,\n",
    "    bf16=True,\n",
    "    tf32=True,\n",
    "    max_grad_norm=0.3,\n",
    "    warmup_ratio=0.03,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    disable_tqdm=False\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    peft_config=peft_config,\n",
    "    max_seq_length=2048,\n",
    "    tokenizer=tokenizer,\n",
    "    packing=True,\n",
    "    formatting_func=format_instruction,\n",
    "    args=model_args,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715ef1e5-8832-457e-86dc-88dbab1e3085",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cff0b62e-3159-4f3e-aedc-e1678832f327",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = \"Explain the rationale behind the last move from the given chess moves in Algebraic notation -\"\n",
    "test_moves = \"d4 d5 c4 c6 cxd5 e6 dxe6 fxe6 Nf3 Bb4+ Nc3 Ba5 Bf4\"\n",
    "test_prompt = f\"\"\" {test_input}\n",
    "        ### Input:\n",
    "        {test_moves}\n",
    "\n",
    "        ### Response:\n",
    "\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84a3a6bc-0eb3-4882-8859-df7e1f14a749",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(test_prompt, return_tensors=\"pt\", truncation=True).input_ids.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b18a82f3-85f4-483e-919d-499dc864cfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/home/s448780/miniconda3/envs/pydev/lib/python3.8/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/s448780/miniconda3/envs/pydev/lib/python3.8/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    outputs = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_new_tokens=2048,\n",
    "        do_sample=True, \n",
    "        top_p=0.9,\n",
    "        temperature=0.9\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f152271-e45c-45cd-a14c-b21c95576a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Explain the rationale behind the last move from the given chess moves in Algebraic notation -\n",
      "        ### Input:\n",
      "        d4 d5 c4 c6 cxd5 e6 dxe6 fxe6 Nf3 Bb4+ Nc3 Ba5 Bf4\n",
      "\n",
      "        ### Response:\n",
      "\n",
      "    1. **White: d4, Black: d5**\n",
      "        - **White:** Opens the center and aims for control.\n",
      "        - **Black:** Mirrors Whiteâ€™s move to contest the center.\n",
      "    2. **White: c4, Black: c6**\n",
      "        - **White:** Initiates the Queenâ€™s Gambit, offering a pawn to challenge Black's central pawns.\n",
      "        - **Black:** Supports the pawn on d5 and prepares to challenge Whiteâ€™s pawn structure.\n",
      "    3. **White: cxd5, Black: e6**\n",
      "        - **White:** Exchanges the pawn to gain space and undermine Black's center.\n",
      "        - **Black:** Recaptures the pawn and opens lines for the bishop and queen.\n",
      "    4. **White: dxe6, Black: fxe6**\n",
      "        - **White:** Further weakens Blackâ€™s pawn structure and opens lines for development.\n",
      "        - **Black:** Recaptures the pawn, opening lines for the queen and maintaining pawn structure.\n",
      "    5. **White: Nf3, Black: Bb4+**\n",
      "        - **White:** Develops the knight, preparing to castle and control the center.\n",
      "        - **Black:** Checks White, forcing a move and disrupting castling plans.\n",
      "    6. **White: Nc3, Black: Ba5**\n",
      "        - **White:** Blocks the check, developing a piece.\n",
      "        - **Black:** Moves the bishop to maintain pressure on the knight and control the a5-e1 diagonal.\n",
      "    7. **White: Bf4**\n",
      "        - **White:** Develops the bishop, aiming at the weak c7 pawn and preparing to castle.\n",
      "\n",
      "    \n",
      "        ### Summary of Strategy Used and Winner:\n",
      "        **Strategies Used:**\n",
      "        - **White:**\n",
      "          - Queenâ€™s Gambit to challenge Blackâ€™s center.\n",
      "          - Piece exchanges to weaken Blackâ€™s pawn structure.\n",
      "          - Development of pieces to control key squares and prepare for castling.\n",
      "        - **Black:**\n",
      "          - Contests the center with pawns.\n",
      "          - Uses tactical motifs (Bb4+) to disrupt White's plans.\n",
      "          - Maintains pawn structure and piece activity.\n",
      "\n",
      "        **Winner:**\n",
      "        - The provided sequence of moves does not indicate a clear winner yet as the game is still in its opening phase with approximately equal chances for both sides. Further moves would be required to determine the winner.\n",
      "\n",
      "        The provided moves demonstrate strategic depth from both players, and the game is poised for an interesting middle game.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5633417b-6e08-4b01-ae56-92ab050a936c",
   "metadata": {},
   "source": [
    "## saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f05115b5-207e-45e5-bb04-cdb5251fea3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s448780/miniconda3/envs/pydev/lib/python3.8/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2000f7be-d2ff-474f-9bc4-7378d64383d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/s448780/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00bbe961-fb68-4921-81ff-db9237ccebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_repo = \"adnaan525/mistral_ACIS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d874214b-7a73-4fc8-ae3f-c09e9fa282bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "391e813b50c74af49b4b8271eb872fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/865M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c69de4d20ea145789520dd5d081aced6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43dd628a2444436094614dc3fac79e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/adnaan525/mistral_7b_ACIS/commit/9455cdcbb7a79a5e2c3cb9fb65f4994e6e458640', commit_message='Upload tokenizer', commit_description='', oid='9455cdcbb7a79a5e2c3cb9fb65f4994e6e458640', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.push_to_hub(\"mistral_7b_ACIS\")\n",
    "tokenizer.push_to_hub(\"mistral_7b_ACIS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2875a8-32e6-43a1-a8de-754c8ba9708f",
   "metadata": {},
   "source": [
    "## testing different prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f966b89b-1fae-4072-944f-f6ed9401af73",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = \"Assume you are a chess master. can you suggest what should be the next move? \"\n",
    "test_moves = \"d4 d5 c4 c6 cxd5 e6 dxe6 fxe6 Nf3 Bb4+ Nc3 Ba5 Bf4\"\n",
    "test_prompt = f\"\"\" {test_input}\n",
    "        ### Input:\n",
    "        {test_moves}\n",
    "\n",
    "        ### Response:\n",
    "\n",
    "    \"\"\"\n",
    "input_ids = tokenizer(test_prompt, return_tensors=\"pt\", truncation=True).input_ids.to(\"cuda:0\")\n",
    "with torch.inference_mode():\n",
    "    outputs = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_new_tokens=2048,\n",
    "        do_sample=True, \n",
    "        top_p=0.9,\n",
    "        temperature=0.9\n",
    "    )\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c887e8-fd67-4d9c-9861-465ed1a6acdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Assume you are a chess master. can you suggest what should be the next move? \n",
    "#         ### Input:\n",
    "#         d4 d5 c4 c6 cxd5 e6 dxe6 fxe6 Nf3 Bb4+ Nc3 Ba5 Bf4\n",
    "\n",
    "#         ### Response:\n",
    "\n",
    "#      ### Game Analysis\n",
    "\n",
    "# 1. **White: d4, Black: d5**\n",
    "#    - **White's Move**: Opening with the Queen's Pawn to control the center.\n",
    "#    - **Black's Move**: Responds symmetrically to contest the center.\n",
    "\n",
    "# 2. **White: c4, Black: c6**\n",
    "#    - **White's Move**: Prepares the Queen's Gambit to challenge Black's center.\n",
    "#    - **Black's Move**: Prepares to fianchetto the King's Bishop and supports the center.\n",
    "\n",
    "# 3. **White: cxd5, Black: e6**\n",
    "#    - **White's Move**: Accepts the gambit and challenges Black's center pawns.\n",
    "#    - **Black's Move**: Prepares to recapture the gambit pawn and solidifies the center.\n",
    "\n",
    "# 4. **White: dxe6, Black: fxe6**\n",
    "#    - **White's Move**: Exchanges the gambit pawn to weaken Black's pawn structure.\n",
    "#    - **Black's Move**: Recaptures the pawn, opening the f-file for the Rook.\n",
    "\n",
    "# 5. **White: Nf3, Black: Bb4+**\n",
    "#    - **White's Move**: Develops a knight, preparing to castle.\n",
    "#    - **Black's Move**: Pins the knight to the king, creating pressure.\n",
    "\n",
    "# 6. **White: Nc3, Black: Ba5**\n",
    "#    - **White's Move**: Defends the knight and further develops.\n",
    "#    - **Black's Move**: Moves the bishop, maintaining the pin and potential pressure on the d4 pawn.\n",
    "\n",
    "# 7. **White: Bf4**\n",
    "#    - **White's Move**: Develops the bishop, aiming to control the e5 square and prepare for further attack.\n",
    "\n",
    "# ### Summary of Strategy Used and Winner\n",
    "\n",
    "# #### Strategies:\n",
    "# - **White's Strategy**: Early central control, aggressive gambit play to weaken Black's pawn structure, and rapid development.\n",
    "# - **Black's Strategy**: Fianchetto to control the center, counter-gambit to challenge Whiteâ€™s aggression, and maintain pressure through pins and potential threats.\n",
    "\n",
    "# #### Winner:\n",
    "# Determining the winner requires further moves and strategic depth. However, at this stage, both players have developed pieces and controlled the center, and the game is open for continued development. The winner would depend on subsequent moves and tactics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
